{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a51a30b-fd7e-4640-8665-70a1ff43862d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torch.optim as optims\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import time\n",
    "from sklearn.linear_model import Lasso,LassoCV, LassoLarsIC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.special import jv,yv\n",
    "torch.set_printoptions(precision=8)\n",
    "torch.manual_seed(1)\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "torch.set_default_dtype(torch.float64)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# plt.rcParams['font.sans-serif'] = 'Microsoft YaHei' #'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pi = math.pi\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa33bbd-0287-4e88-95d8-cbb5de90ec79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_bd = 0.0\n",
    "r_bd = 1.0\n",
    "\n",
    "#解析解的波源中心\n",
    "exact_center = torch.tensor([\n",
    "        [0.31513261, 0.26611714, 0.85142870],\n",
    "        [0.57929771, 0.72004628, 0.84741592],\n",
    "        [0.15307150, 0.15811884, 0.12572213],\n",
    "        [0.80129063, 0.21860302, 0.11104541],\n",
    "        [0.94752561, 0.75961257, 0.35874126],],dtype=torch.float64)\n",
    "\n",
    "exact_hight = torch.tensor([1.0,1.0,1.0,1.0,1.0],dtype=torch.float64)\n",
    "\n",
    "def xyToPolar(X,c):\n",
    "    x = X[:,0].reshape(-1,1)\n",
    "    y = X[:,1].reshape(-1,1)\n",
    "    z = X[:,2].reshape(-1,1)\n",
    "    return torch.sqrt(x**2+y**2+z**2)\n",
    "\n",
    "def xycToPolar(X,c):\n",
    "    x = X[:,0].reshape(-1,1)\n",
    "    y = X[:,1].reshape(-1,1)\n",
    "    z = X[:,2].reshape(-1,1)\n",
    "    return torch.sqrt((x.unsqueeze(1)-c[:,0].reshape(-1,1))**2+\\\n",
    "                      (y.unsqueeze(1)-c[:,1].reshape(-1,1))**2+\\\n",
    "                      (z.unsqueeze(1)-c[:,2].reshape(-1,1))**2).squeeze(-1)\n",
    "\n",
    "#SFSNN的输出\n",
    "def get_u(X,c,h):\n",
    "    r = xycToPolar(X,c)\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = torch.sin(k*r)/r\n",
    "    u = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u\n",
    "\n",
    "#SFSNN的输出对x的导数\n",
    "def get_u_dx(X,c,h):\n",
    "    x = X[:,0].reshape(-1,1)-c[:,0].reshape(1,-1)\n",
    "    r = xycToPolar(X,c) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = (k*x*r*torch.cos(k*r)-torch.sin(k*r)*x)/r**3\n",
    "    u_dx = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u_dx\n",
    "\n",
    "#SFSNN的输出对y的导数\n",
    "def get_u_dy(X,c,h):\n",
    "    y = X[:,1].reshape(-1,1)-c[:,1].reshape(1,-1)\n",
    "    r = xycToPolar(X,c) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = (k*y*r*torch.cos(k*r)-torch.sin(k*r)*y)/r**3\n",
    "    u_dy = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u_dy\n",
    "\n",
    "#SFSNN的输出对z的导数\n",
    "def get_u_dz(X,c,h):\n",
    "    z = X[:,2].reshape(-1,1)-c[:,2].reshape(1,-1)\n",
    "    r = xycToPolar(X,c) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = (k*z*r*torch.cos(k*r)-torch.sin(k*r)*z)/r**3\n",
    "    u_dz = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u_dz\n",
    "\n",
    "#定义解析解\n",
    "def u_exact(X):\n",
    "    r = xycToPolar(X,exact_center)\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = torch.sin(k*r)/r\n",
    "    u = torch.matmul(Phi,exact_hight).reshape(-1,1)\n",
    "    return u\n",
    "\n",
    "#定义解析解对x的导数\n",
    "def u_dx_exact(X):\n",
    "    x = X[:,0].reshape(-1,1)-exact_center[:,0].reshape(1,-1)\n",
    "    r = xycToPolar(X,exact_center) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = (k*x*r*torch.cos(k*r)-torch.sin(k*r)*x)/r**3\n",
    "    u_dx = torch.matmul(Phi,exact_hight).reshape(-1,1)\n",
    "    return u_dx\n",
    "\n",
    "#定义解析解对y的导数\n",
    "def u_dy_exact(X):\n",
    "    y = X[:,1].reshape(-1,1)-exact_center[:,1].reshape(1,-1)\n",
    "    r = xycToPolar(X,exact_center) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = (k*y*r*torch.cos(k*r)-torch.sin(k*r)*y)/r**3\n",
    "    u_dy = torch.matmul(Phi,exact_hight).reshape(-1,1)\n",
    "    return u_dy\n",
    "\n",
    "#定义解析解对z的导数\n",
    "def u_dz_exact(X):\n",
    "    z = X[:,2].reshape(-1,1)-exact_center[:,2].reshape(1,-1)\n",
    "    r = xycToPolar(X,exact_center) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = (k*z*r*torch.cos(k*r)-torch.sin(k*r)*z)/r**3\n",
    "    u_dz = torch.matmul(Phi,exact_hight).reshape(-1,1)\n",
    "    return u_dz\n",
    "\n",
    "#SFSNN的网络输出对参数c的梯度\n",
    "def get_u_dc(X,c,h):\n",
    "    x = -(X[:,0].reshape(-1,1)-c[:,0].reshape(1,-1))\n",
    "    y = -(X[:,1].reshape(-1,1)-c[:,1].reshape(1,-1))\n",
    "    z = -(X[:,2].reshape(-1,1)-c[:,2].reshape(1,-1))\n",
    "    r = xycToPolar(X,c) #m*n\n",
    "    r[r==0] = 1e-15\n",
    "    Phi_1 = h*(k*x*r*torch.cos(k*r)-torch.sin(k*r)*x)/r**3\n",
    "    Phi_2 = h*(k*y*r*torch.cos(k*r)-torch.sin(k*r)*y)/r**3\n",
    "    Phi_3 = h*(k*z*r*torch.cos(k*r)-torch.sin(k*r)*z)/r**3\n",
    "    return torch.cat((Phi_1.unsqueeze(-1),Phi_2.unsqueeze(-1),Phi_3.unsqueeze(-1)),-1)\n",
    "    \n",
    "#SFSNN的网络输出对参数w的梯度\n",
    "def get_u_dh(X,c):\n",
    "    r = xycToPolar(X,c)\n",
    "    r[r==0] = 1e-15\n",
    "    Phi = torch.sin(k*r)/r\n",
    "    return Phi\n",
    "\n",
    "#采样边界点\n",
    "def SampleBoundPoints(n_bd=100):\n",
    "    torch.manual_seed(1)\n",
    "    x = torch.linspace(l_bd,r_bd,n_bd)\n",
    "    mx,my = torch.meshgrid((x,x))\n",
    "    mx,my = mx.reshape(-1,1),my.reshape(-1,1)\n",
    "    z = torch.zeros_like(mx)\n",
    "    X_1 = torch.cat((mx, my,z), dim=1)  # (x,y,0)\n",
    "    X_2 = torch.cat((mx, my,z+1), dim=1)  # (x,y,1)\n",
    "    X_3 = torch.cat((mx, z+1,my), dim=1)  # (x,1,z)\n",
    "    X_4 = torch.cat((mx, z,my), dim=1)  # (x,0,z)\n",
    "    X_5 = torch.cat((z, mx,my), dim=1)  # (0,y,z)\n",
    "    X_6 = torch.cat((z+1 , mx,my), dim=1)  # (1,y,z)\n",
    "    x_bd = torch.cat((X_1,X_2,X_3,X_4,X_5,X_6),0) \n",
    "    return x_bd\n",
    "\n",
    "#生成边界控制项\n",
    "def generate_bd_term(x_bd):\n",
    "    g = u_exact(x_bd)  #迪利克雷边界项\n",
    "    return g\n",
    "\n",
    "#计算相对误差\n",
    "def test_err(net,batch=2000,n=100):\n",
    "    x0 = torch.linspace(l_bd, r_bd, n)\n",
    "    mx, my,mz = torch.meshgrid(x0, x0,x0)\n",
    "    X = torch.cat((mx.reshape(-1,1),my.reshape(-1,1),mz.reshape(-1,1)),1)\n",
    "    u_ex = u_exact(X).flatten()\n",
    "    u_dx_ex = u_dx_exact(X).flatten()\n",
    "    u_dy_ex = u_dy_exact(X).flatten()\n",
    "    u_dz_ex = u_dz_exact(X).flatten()\n",
    "    u_ex = u_ex.to(device)\n",
    "    u_dx_ex = u_dx_ex.to(device)\n",
    "    u_dy_ex = u_dy_ex.to(device)\n",
    "    u_dz_ex = u_dz_ex.to(device)\n",
    "    net = net.to(device)\n",
    "    use_batch=True\n",
    "    with torch.no_grad():\n",
    "        if use_batch:\n",
    "            dataset = Data.TensorDataset(X)\n",
    "            data_iter = Data.DataLoader(dataset=dataset, batch_size=batch, shuffle=False)\n",
    "            u = None\n",
    "            u_dx = None\n",
    "            u_dy = None\n",
    "            u_dz = None\n",
    "            for x in data_iter:\n",
    "                x_part = x[0].to(device)\n",
    "                u_part = net(x_part).flatten()\n",
    "                u_dx_part = net.cal_dx(x_part).flatten()\n",
    "                u_dy_part = net.cal_dy(x_part).flatten()\n",
    "                u_dz_part = net.cal_dz(x_part).flatten()\n",
    "                if u is None:\n",
    "                    u = u_part\n",
    "                    u_dx = u_dx_part\n",
    "                    u_dy = u_dy_part\n",
    "                    u_dz = u_dz_part\n",
    "                else:\n",
    "                    u = torch.cat((u,u_part),0)\n",
    "                    u_dx =  torch.cat((u_dx,u_dx_part),0)\n",
    "                    u_dy =  torch.cat((u_dy,u_dy_part),0)\n",
    "                    u_dz =  torch.cat((u_dz,u_dz_part),0)\n",
    "                torch.cuda.empty_cache()\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "            u = net(X).flatten()\n",
    "            u_dx = net.cal_dx(X).flatten()\n",
    "            u_dy = net.cal_dy(X).flatten()\n",
    "            u_dz = net.cal_dz(X).flatten()\n",
    "    torch.cuda.empty_cache()\n",
    "    Rel_L2 = torch.norm(u_ex-u)/torch.norm(u_ex)  \n",
    "    Rel_Li = torch.max(torch.abs(u-u_ex))/torch.max(torch.abs(u_ex))\n",
    "    Rel_H1 = torch.sqrt(torch.norm(u_ex-u)**2+torch.norm(u_dx_ex-u_dx)**2+torch.norm(u_dy_ex-u_dy)**2+torch.norm(u_dz_ex-u_dz)**2)/\\\n",
    "                torch.sqrt(torch.norm(u_ex)**2+ torch.norm(u_dx_ex)**2+torch.norm(u_dy_ex)**2+torch.norm(u_dz_ex)**2)\n",
    "    print(\"Rel.L2=\",Rel_L2.cpu(),\",Rel.Li=\",Rel_Li.cpu(),\",Rel.H1=\",Rel_H1.cpu())\n",
    "    losswriter.add_scalar('Rel_L2',Rel_L2.cpu().item())\n",
    "    losswriter.add_scalar('Rel_Li',Rel_Li.cpu().item())\n",
    "    losswriter.add_scalar('Rel_H1',Rel_H1.cpu().item())\n",
    "    return Rel_L2,Rel_Li,Rel_H1\n",
    "\n",
    "#去除无效基函数\n",
    "def drop_bf(net,tol=10):\n",
    "    if tol>1:\n",
    "        if tol>=net.hight.data.shape[0]:\n",
    "            return net\n",
    "        net = net.cpu()\n",
    "        print(f'The number of RBFs before discarding：{net.hight.shape[0]}')\n",
    "        c, h = net.center.detach(), net.hight.detach()\n",
    "        top_values, index = torch.topk(abs(h), k=tol, largest=True)\n",
    "        c1 = torch.index_select(c, 0, index)\n",
    "        h1 = torch.index_select(h, 0, index)\n",
    "        net.center = nn.Parameter(c1)\n",
    "        net.hight = nn.Parameter(h1)\n",
    "        print(f'The number of RBFs after discarding：{net.hight.shape[0]}')\n",
    "    else:\n",
    "        net = net.cpu()\n",
    "        print(f'The number of RBFs before discarding：{net.hight.shape[0]}')\n",
    "        c, h = net.center.detach(), net.hight.detach()\n",
    "        index = torch.where(abs(h) > tol)[0]\n",
    "        c1 = torch.index_select(c, 0, index)\n",
    "        h1 = torch.index_select(h, 0, index)\n",
    "        net.center = nn.Parameter(c1)\n",
    "        net.hight = nn.Parameter(h1)\n",
    "        print(f'The number of RBFs after discarding：{net.hight.shape[0]}')\n",
    "    return net\n",
    "\n",
    "#初始化基函数的中心分布\n",
    "def generate_center(N):\n",
    "    x0 = torch.linspace(0,1,N)\n",
    "    mx,my,mz = torch.meshgrid((x0,x0,x0))\n",
    "    center = torch.cat((mx.reshape(-1,1),my.reshape(-1,1),mz.reshape(-1,1)),1)\n",
    "    # if N >n**2:\n",
    "    #     c1 = torch.rand(N-n**2,2)\n",
    "    #     center = torch.cat((mx.reshape(-1,1),my.reshape(-1,1)),1)\n",
    "    #     center = torch.cat((center,c1),0)\n",
    "    return center\n",
    "\n",
    "#初始化SFSNN网络\n",
    "class BesselNet(torch.nn.Module):\n",
    "    def __init__(self,N=32):\n",
    "        super(BesselNet, self).__init__()\n",
    "        torch.manual_seed(1)\n",
    "        # self.center = nn.Parameter((r_bd-l_bd)*torch.rand(N,3)+l_bd)\n",
    "        self.center = nn.Parameter(generate_center(N))\n",
    "        self.hight = nn.Parameter(torch.rand(N**3,dtype=torch.float64))\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = get_u(x,self.center,self.hight)\n",
    "        return u\n",
    "\n",
    "    def cal_dx(self,x):\n",
    "        return get_u_dx(x,net.center,net.hight)\n",
    "\n",
    "    def cal_dy(self,x):\n",
    "        return get_u_dy(x,net.center,net.hight)\n",
    "\n",
    "    def cal_dz(self,x):\n",
    "        return get_u_dz(x,net.center,net.hight)\n",
    "\n",
    "#计算LASSO问题的系数矩阵和右端向量\n",
    "def cal_Jacobi(net,x_bd):\n",
    "    with torch.no_grad():\n",
    "        A = get_u_dh(x_bd,net.center.data)\n",
    "        f = generate_bd_term(x_bd)\n",
    "    print('A.shape',A.shape,f.shape)\n",
    "    return A.detach(),f.detach()\n",
    "\n",
    "#求解线性最小二乘问题：Ax=f\n",
    "def solve_coeff(net,A,f):  #solve  Ax=f\n",
    "    test_err(net)\n",
    "    net = net.cpu()\n",
    "    print(\"A的条件数=\",torch.linalg.cond(A))\n",
    "    index1 = torch.where(abs(net.hight) > 1e-5)[0]\n",
    "    print(\"初始有效基函数个数=\",index1.shape[0])\n",
    "    err_ini = torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f)\n",
    "    print(\"初始误差,err_norm=\",torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f))\n",
    "    t1 = time.time()\n",
    "    \n",
    "    bestP = torch.linalg.lstsq(A,f,driver='gelsd')[0] #‘gels’ , ‘gelsy’ , ‘gelsd , ‘gelss’\n",
    "    t2 = time.time()\n",
    "    print(\"solve time=\",t2-t1)\n",
    "    net.hight = nn.Parameter(bestP.flatten())\n",
    "    print(\"admm优化后,err_norm=\",torch.norm(torch.matmul(A,bestP).reshape(-1,1)-f))\n",
    "    print(\"admm优化后,相对误差:\")\n",
    "    test_err(net)\n",
    "    net = net.to(device)\n",
    "    return net\n",
    "\n",
    "#记录损失\n",
    "class LossWriter:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = {}\n",
    "\n",
    "    def add_scalar(self, tag, scalar_value):\n",
    "        if tag not in self.data:\n",
    "            self.data[tag] = []\n",
    "        self.data[tag].append(scalar_value)\n",
    "        \n",
    "    def save(self):\n",
    "        # 保存数据为npz格式\n",
    "        np.savez(self.filename, **self.data)\n",
    "\n",
    "\n",
    "##求解LASSO问题：||Ax-f||+\\lam||x||_1\n",
    "def solve_coeff_lasso(net,A,f,lam=0.001,cri=None):  #solve  Ax=f\n",
    "    test_err(net)\n",
    "    net = net.cpu()\n",
    "    print(\"A的条件数=\",torch.linalg.cond(A))\n",
    "    index1 = torch.where(abs(net.hight) > 1e-5)[0]\n",
    "    print(\"初始有效基函数个数=\",index1.shape[0])\n",
    "    err_ini = torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f)\n",
    "    print(\"初始误差,err_norm=\",torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f))\n",
    "    if cri=='aic':\n",
    "        clf = LassoLarsIC('aic',fit_intercept=False)\n",
    "        clf.fit(A,f)  \n",
    "        print('使用aic,最佳的lam=',clf.alpha_)\n",
    "    elif cri=='bic':\n",
    "        clf = LassoLarsIC('bic',fit_intercept=False)\n",
    "        clf.fit(A,f)  \n",
    "        print('使用bic,最佳的lam=',clf.alpha_)\n",
    "    else:\n",
    "        clf = Lasso(lam,fit_intercept=False)\n",
    "        clf.fit(A,f) \n",
    "        print('使用指定的lam=',lam)\n",
    "    h = torch.tensor(clf.coef_)\n",
    "    net.hight = nn.Parameter(h.flatten())\n",
    "    print(\"admm优化后,err_norm=\",torch.norm(torch.matmul(A,h).reshape(-1,1)-f))\n",
    "    print(\"admm优化后,相对误差:\")\n",
    "    test_err(net)\n",
    "    net = net.to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a99ecf2-f064-45ec-9e2f-bc909b3effa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rel.L2= tensor(6.63276602e-12) ,Rel.Li= tensor(9.61212275e-12) ,Rel.H1= tensor(6.62632194e-12)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'losswriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 165\u001b[0m\n\u001b[0;32m    163\u001b[0m net \u001b[38;5;241m=\u001b[39m BesselNet(N)\n\u001b[0;32m    164\u001b[0m net \u001b[38;5;241m=\u001b[39m load_model(net)\n\u001b[1;32m--> 165\u001b[0m test_err(net)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    167\u001b[0m plot_center(net,save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs/2d_exam4/k_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_final_center.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mk)\n",
      "Cell \u001b[1;32mIn[2], line 177\u001b[0m, in \u001b[0;36mtest_err\u001b[1;34m(net, batch, n)\u001b[0m\n\u001b[0;32m    174\u001b[0m Rel_H1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mnorm(u_ex\u001b[38;5;241m-\u001b[39mu)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dx_ex\u001b[38;5;241m-\u001b[39mu_dx)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dy_ex\u001b[38;5;241m-\u001b[39mu_dy)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dz_ex\u001b[38;5;241m-\u001b[39mu_dz)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\\\n\u001b[0;32m    175\u001b[0m             torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mnorm(u_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(u_dx_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dy_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dz_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRel.L2=\u001b[39m\u001b[38;5;124m\"\u001b[39m,Rel_L2\u001b[38;5;241m.\u001b[39mcpu(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Rel.Li=\u001b[39m\u001b[38;5;124m\"\u001b[39m,Rel_Li\u001b[38;5;241m.\u001b[39mcpu(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Rel.H1=\u001b[39m\u001b[38;5;124m\"\u001b[39m,Rel_H1\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m--> 177\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRel_L2\u001b[39m\u001b[38;5;124m'\u001b[39m,Rel_L2\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    178\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRel_Li\u001b[39m\u001b[38;5;124m'\u001b[39m,Rel_Li\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    179\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRel_H1\u001b[39m\u001b[38;5;124m'\u001b[39m,Rel_H1\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'losswriter' is not defined"
     ]
    }
   ],
   "source": [
    "def caldc(c1,c2):\n",
    "    dc = (abs(c1-c2)).sum(-1)\n",
    "    print(\"center变动最大的:\",torch.max(dc).cpu().item())\n",
    "\n",
    "def caldh(h1,h2):\n",
    "    print(\"hight中变动最大的:\",torch.max(abs(h1-h2)).cpu().item())\n",
    "\n",
    "#合并基函数\n",
    "def merge_bf(center,hight,tol=0.01):\n",
    "    distances = torch.cdist(center,center)\n",
    "    # print(distances)\n",
    "    c_new,h_new = [],[]\n",
    "    index = torch.arange(distances.shape[0])\n",
    "    i = 0\n",
    "    while (len(index)>0)&(i<hight.shape[0]):\n",
    "        dis = distances[i,:]\n",
    "        index_i = torch.where(dis<tol)[0]\n",
    "        c = 0\n",
    "        h = 0\n",
    "        # print('i=',i,'dis=',dis)\n",
    "        num= len(index)\n",
    "        for j in index_i:\n",
    "            if j not in index:\n",
    "                continue\n",
    "            c += center[j,:]\n",
    "            h += hight[j]\n",
    "            if len(index)==1:\n",
    "                index= []\n",
    "            else:\n",
    "                index_del = np.where(index==j)\n",
    "                index = np.delete(index,index_del) \n",
    "            # print('j=',j,'index=',index)\n",
    "        # print(min(len(index_i),num))\n",
    "        # print('c1=',c/min(len(index_i),num),'h1=',h)\n",
    "        c_new.append(c/min(len(index_i),num))\n",
    "        h_new.append(h)\n",
    "        # print('index=',index,len(index))\n",
    "        if len(index)>0:\n",
    "            i = index[0]\n",
    "        else:\n",
    "            i = i+1\n",
    "    c_new = torch.tensor(np.array(c_new))\n",
    "    h_new = torch.tensor(np.array(h_new))\n",
    "    print('合并前的中心=',center,'合并前的系数=',hight)\n",
    "    print('合并后的中心=',c_new,'合并后的系数=',h_new)\n",
    "    return c_new,h_new\n",
    "    \n",
    "#训练SFSNN网络\n",
    "def train(net,x_bd,losswriter,lr,MaxNiter,lam,tol,tol_c):\n",
    "    t_all = 0.0\n",
    "    test_err(net)\n",
    "    g = generate_bd_term(x_bd)   #边界控制项\n",
    "    g = g.to(device)\n",
    "    net = net.to(device)\n",
    "    optimizer = optims.Adam([{\"params\":net.center,\"lr\":lr},{\"params\":net.hight,\"lr\":lr}])\n",
    "    x_bd = x_bd.to(device)\n",
    "    for Niter in range(1, MaxNiter):\n",
    "        l_bd_sum = 0.0\n",
    "        t1 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            u_bd = get_u(x_bd,net.center,net.hight)  \n",
    "            u_bd_dc = get_u_dc(x_bd,net.center,net.hight)\n",
    "            u_bd_dh = get_u_dh(x_bd,net.center)\n",
    "        c1 = net.center.clone()\n",
    "        h1 = net.hight.clone()\n",
    "        l_bd = ((u_bd-g)**2).sum() \n",
    "        net.center.grad = (2*(u_bd-g).unsqueeze(-1)*u_bd_dc).sum(0)\n",
    "        net.hight.grad = (2*(u_bd-g)*u_bd_dh).sum(0)\n",
    "        optimizer.step()\n",
    "        c2 = net.center.data\n",
    "        h2 = net.hight.data\n",
    "       \n",
    "        t2 = time.time()\n",
    "        t_all += t2-t1\n",
    "        if (Niter%200==0)&(optimizer.param_groups[0]['lr']>=0.0001):\n",
    "            for i in range(len(optimizer.param_groups)):\n",
    "                optimizer.param_groups[i]['lr']=0.1*optimizer.param_groups[i]['lr']\n",
    "        print('k=%d,t_all=%.3f,t_Niter=%.3f,Niter:%d,l_bd:%.8f,lr:%.8f' \n",
    "            % (k,t_all,t2-t1, Niter, l_bd.cpu().item(),optimizer.param_groups[0]['lr']))\n",
    "        losswriter.add_scalar('loss', l_bd.cpu().item())\n",
    "        if Niter%10==0:\n",
    "            torch.save(net.state_dict(), 'model/2d_exam7_%d.pth'%int(k))\n",
    "            test_err(net)\n",
    "            losswriter.save()\n",
    "            # caldc(c1,c2)\n",
    "            # caldh(h1,h2)\n",
    "            print('center=',net.center.data,'hight=',net.hight.data)\n",
    "            plot_center(net)\n",
    "            losswriter.add_scalar('N_bf',net.hight.data.cpu().shape[0])\n",
    "        torch.cuda.empty_cache()   \n",
    "        if (Niter%700==0)&(net.hight.shape[0]>1)&(Niter<MaxNiter-1000):\n",
    "            net = net.cpu()\n",
    "            net = drop_bf(net,tol)\n",
    "            center_new,hight_new = merge_bf(net.center.data,net.hight.data,tol_c)\n",
    "            net.center = nn.Parameter(center_new)\n",
    "            net.hight = nn.Parameter(hight_new)\n",
    "            A,f = cal_Jacobi(net,x_bd.cpu())\n",
    "            net = solve_coeff_lasso(net,A,f,lam)\n",
    "            net = drop_bf(net,tol)\n",
    "            plot_center(net)\n",
    "            print('center=',net.center.data,'hight=',net.hight.data)\n",
    "            net = net.to(device)\n",
    "            optimizer = optims.Adam([{\"params\":net.center,\"lr\":lr},\\\n",
    "                                     {\"params\":net.hight,\"lr\":lr}])\n",
    "    net = net.cpu()\n",
    "    x_bd = x_bd.cpu()\n",
    "    A,f = cal_Jacobi(net,x_bd)\n",
    "    net = solve_coeff(net,A,f)\n",
    "    torch.save(net.state_dict(), 'model/2d_exam7_%d.pth'%int(k))\n",
    "    test_err(net)\n",
    "    losswriter.save()\n",
    "    plot_center(net,save_path='imgs/2d_exam7/k_%d_final_center.png'%k)\n",
    "    return net\n",
    "    \n",
    "#绘制基函数的中心分布\n",
    "def plot_center(net,num=5,save_path=None):\n",
    "    # index = torch.where(abs(net.hight.data.cpu()) > 1e-5)[0]\n",
    "    top_values, index = torch.topk(abs(net.hight.data.cpu()), k=num, largest=True)\n",
    "    # print('前8个基函数系数=',top_values,',所有系数=',net.hight.data.cpu())\n",
    "    print('总基函数个数:',net.hight.shape[0],'绘制前%d个基函数'%num)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')# 创建一个图形和一个3D坐标轴\n",
    "    # 绘制3D散点图\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    # print(exact_center,net.center.data)\n",
    "    ax.scatter(exact_center[:,0],exact_center[:,1],exact_center[:,2],c='r',marker='o',label='wave_source')\n",
    "    blue_label_added = False\n",
    "    yellow_label_added = False\n",
    "    for i in range(len(net.hight.data.cpu())):\n",
    "        \n",
    "        if not yellow_label_added:\n",
    "            ax.scatter(net.center.data.cpu()[i,0],net.center.data.cpu()[i,1],net.center.data.cpu()[i,2],c='b',marker='+',label='pred_wave_source')\n",
    "            yellow_label_added = True\n",
    "        else:\n",
    "            ax.scatter(net.center.data.cpu()[i,0],net.center.data.cpu()[i,1],net.center.data.cpu()[i,2],c='b',marker='+')\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_zlim([0,1])\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def load_model(net):\n",
    "    model = torch.load('model/2d_exam7/2d_exam7_%d.pth'%int(k))\n",
    "    net.center = nn.Parameter(model['center'])\n",
    "    net.hight = nn.Parameter(model['hight'])\n",
    "    return net\n",
    "\n",
    "k = 100\n",
    "lr = 0.01\n",
    "MaxNiter = 3000\n",
    "n_bd = k\n",
    "N = 20\n",
    "tol = 0.001\n",
    "tol_c = 0.5/20\n",
    "torch.manual_seed(1)\n",
    "lam = 0.1 #0.1,0.01,,0.0001,0.00001,0.000001\n",
    "\n",
    "x_bd = SampleBoundPoints(n_bd)\n",
    "net = BesselNet(N)\n",
    "net = load_model(net)\n",
    "test_err(net)\n",
    "\n",
    "plot_center(net,save_path='imgs/2d_exam7/k_%d_final_center.png'%k)\n",
    "losswriter = LossWriter('loss/loss_exam7_%d_%d.npz'%(k,N))\n",
    "losswriter.add_scalar('k',k)\n",
    "losswriter.add_scalar('MaxNiter',MaxNiter)\n",
    "losswriter.add_scalar('n_bd',n_bd)\n",
    "losswriter.add_scalar('lr',lr)\n",
    "losswriter.add_scalar('N',N)\n",
    "losswriter.add_scalar('lam',N)\n",
    "losswriter.add_scalar('N_bf',net.hight.data.cpu().shape[0])\n",
    "losswriter.add_scalar('tol',tol)\n",
    "losswriter.add_scalar('tol_c',tol_c)\n",
    "\n",
    "# A,f = cal_Jacobi(net,x_bd)\n",
    "# net = solve_coeff_lasso(net,A,f,lam)#,lam\n",
    "# # net = solve_coeff(net,A,f)\n",
    "# net = drop_bf(net,tol)\n",
    "# torch.save(net.state_dict(), 'model/2d_exam7_%d_init.pth'%int(k))\n",
    "# L2,_,_= test_err(net)\n",
    "# print('lam=',lam,',L2=',L2)\n",
    "# plot_center(net,save_path='imgs/2d_exam7/k_%d_init_center.png'%k)\n",
    "# train(net,x_bd,losswriter,lr,MaxNiter,lam,tol,tol_c) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
