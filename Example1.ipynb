{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a51a30b-fd7e-4640-8665-70a1ff43862d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torch.optim as optims\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from sklearn.linear_model import Lasso\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.special import jv,yv\n",
    "torch.set_printoptions(precision=8)\n",
    "torch.manual_seed(1)\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "torch.set_default_dtype(torch.float64)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# plt.rcParams['font.sans-serif'] = 'Microsoft YaHei' #'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa33bbd-0287-4e88-95d8-cbb5de90ec79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_bd = 0.0\n",
    "r_bd = 1.0\n",
    "\n",
    "#0阶第一类贝塞尔函数\n",
    "def Jvs(r):\n",
    "    return torch.special.bessel_j0(r)\n",
    "\n",
    "#0阶第一类贝塞尔函数的导数\n",
    "def Jvs_dr(r):\n",
    "    return -torch.special.bessel_j1(r)\n",
    "\n",
    "\n",
    "def xyToPolar(x,y):\n",
    "    return torch.sqrt(x**2+y**2)\n",
    "\n",
    "def xycToPolar(X,c):\n",
    "    x = X[:,0].reshape(-1,1)\n",
    "    y = X[:,1].reshape(-1,1)\n",
    "    return torch.sqrt((x.unsqueeze(1)-c[:,0].reshape(-1,1))**2+(y.unsqueeze(1)-c[:,1].reshape(-1,1))**2).squeeze(-1)\n",
    "\n",
    "#SFSNN的网络输出\n",
    "def get_u(X,c,h):\n",
    "    r = xycToPolar(X,c)\n",
    "    Phi = Jvs(k*r)\n",
    "    u = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u\n",
    "    \n",
    "#SFSNN的网络输出对x的导数\n",
    "def get_u_dx(X,c,h):\n",
    "    x = X[:,0].reshape(-1,1)\n",
    "    r = xycToPolar(X,c)\n",
    "    r[r == 0] += 1e-10\n",
    "    Phi = k*Jvs_dr(k*r)*(x.unsqueeze(1)-c[:,0].reshape(-1,1)).squeeze(-1)/r\n",
    "    u_dx = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u_dx\n",
    "    \n",
    "#SFSNN的网络输出对y的导数\n",
    "def get_u_dy(X,c,h):\n",
    "    y = X[:,1].reshape(-1,1)\n",
    "    r = xycToPolar(X,c)\n",
    "    r[r == 0] += 1e-10\n",
    "    Phi = k*Jvs_dr(k*r)*(y.unsqueeze(1)-c[:,1].reshape(-1,1)).squeeze(-1)/r\n",
    "    u_dy = torch.matmul(Phi,h).reshape(-1,1)\n",
    "    return u_dy\n",
    "\n",
    "# def Jvs_drr(r,ksi=0):\n",
    "#     return 0.5*(Jvs(r,ksi+2)-Jvs(r,ksi))\n",
    "\n",
    "# def get_u_dxx(X,c,h):\n",
    "#     x = X[:,0].reshape(-1,1)\n",
    "#     r = xycToPolar(X,c)\n",
    "#     r[r == 0] += 1e-9\n",
    "#     Phi = k*Jvs_drr(k*r,0)*((x.unsqueeze(1)-c[:,0].reshape(-1,1)).squeeze(-1)/r)**2+\\\n",
    "#           Jvs_dr(k*r,0)*(r**2-((x.unsqueeze(1)-c[:,0].reshape(-1,1))**2).squeeze(-1))/r**3\n",
    "#     u_dxx = k*torch.matmul(Phi,h).reshape(-1,1)\n",
    "#     return u_dxx\n",
    "    \n",
    "# def get_u_dyy(X,c,h):\n",
    "#     y = X[:,1].reshape(-1,1)\n",
    "#     r = xycToPolar(X,c)\n",
    "#     r[r == 0] += 1e-9\n",
    "#     Phi = k*Jvs_drr(k*r,0)*((y.unsqueeze(1)-c[:,1].reshape(-1,1)).squeeze(-1)/r)**2+\\\n",
    "#           Jvs_dr(k*r,0)*(r**2-((y.unsqueeze(1)-c[:,1].reshape(-1,1))**2).squeeze(-1))/r**3\n",
    "#     u_dxx = k*torch.matmul(Phi,h).reshape(-1,1)\n",
    "#     return u_dxx\n",
    "\n",
    "#SFSNN的网络输出对参数c的梯度\n",
    "def get_u_dc(X,c,h):\n",
    "    x = X[:,0].reshape(-1,1)\n",
    "    y = X[:,1].reshape(-1,1)\n",
    "    r = xycToPolar(X,c)\n",
    "    r[r == 0] += 1e-9\n",
    "    Phi_1 = k*h*Jvs_dr(k*r)*(c[:,0].reshape(-1,1)-x.unsqueeze(1)).squeeze(-1)/r\n",
    "    Phi_2 = k*h*Jvs_dr(k*r)*(c[:,1].reshape(-1,1)-y.unsqueeze(1)).squeeze(-1)/r\n",
    "    return torch.cat((Phi_1.unsqueeze(-1),Phi_2.unsqueeze(-1)),-1)\n",
    "    \n",
    "#SFSNN的网络输出对权重h的导数\n",
    "def get_u_dh(X,c):\n",
    "    r = xycToPolar(X,c)\n",
    "    Phi = Jvs(k*r)   #m*n\n",
    "    return Phi\n",
    "\n",
    "#解析解的两个波源中心\n",
    "exact_center = torch.tensor([[0.34215456124, -0.145154523589],\n",
    "                            [0.74587239231, -0.18451356451]])\n",
    "\n",
    "#定义解析解\n",
    "def u_exact(x):\n",
    "    r = xycToPolar(x.cpu(),exact_center)\n",
    "    u = torch.special.bessel_j0(k*r).sum(-1).reshape(-1,1)\n",
    "    if x.is_cuda:\n",
    "        u = u.to(device)\n",
    "    return u\n",
    "\n",
    "#定义解析解对x的导数，用来计算相对H1误差\n",
    "def u_dx_exact(X):\n",
    "    x = X[:,0].reshape(-1,1)\n",
    "    r = xycToPolar(X,exact_center)\n",
    "    r[r == 0] += 1e-10\n",
    "    Phi = k*Jvs_dr(k*r)*(x.unsqueeze(1)-exact_center[:,0].reshape(-1,1)).squeeze(-1)/r\n",
    "    u_dx = (Phi.sum(-1)).reshape(-1,1)\n",
    "    return u_dx\n",
    "    \n",
    "#定义解析解对y的导数，用来计算相对H1误差\n",
    "def u_dy_exact(X):\n",
    "    y = X[:,1].reshape(-1,1)\n",
    "    r = xycToPolar(X,exact_center)\n",
    "    r[r == 0] += 1e-10\n",
    "    Phi = k*Jvs_dr(k*r)*(y.unsqueeze(1)-exact_center[:,1].reshape(-1,1)).squeeze(-1)/r\n",
    "    u_dy = (Phi.sum(-1)).reshape(-1,1)\n",
    "    return u_dy\n",
    "\n",
    "#采样边界点\n",
    "def SampleBoundPoints(n_bd=2000):\n",
    "    torch.manual_seed(1)\n",
    "    x = torch.linspace(l_bd,r_bd,n_bd,dtype=torch.float64).reshape(-1,1)\n",
    "    y = torch.zeros_like(x,dtype=torch.float64)\n",
    "    X_1 = torch.cat((x, y), dim=1)  # (x,0)\n",
    "    X_2 = torch.cat((y + 1, x), dim=1)  # (1,y)\n",
    "    X_3 = torch.cat((x, y+1), dim=1)  # (x,1)\n",
    "    X_4 = torch.cat((y, x), dim=1)  # (0,y)\n",
    "    x_bd = torch.cat((X_1,X_2,X_3,X_4),0)     #边界样本点\n",
    "    return x_bd\n",
    "\n",
    "\n",
    "#生成边界控制项\n",
    "def generate_bd_term(x_bd):\n",
    "    g = u_exact(x_bd)  #迪利克雷边界项\n",
    "    return g\n",
    "\n",
    "\n",
    "#计算相对误差\n",
    "def test_err(net,n=300):\n",
    "    x0 = torch.linspace(l_bd, r_bd, n)\n",
    "    mx, my = torch.meshgrid(x0, x0)\n",
    "    X = torch.cat((mx.reshape(-1,1),my.reshape(-1,1)),1)\n",
    "    u_ex = u_exact(X).flatten()\n",
    "    u_dx_ex = u_dx_exact(X).flatten()\n",
    "    u_dy_ex = u_dy_exact(X).flatten()\n",
    "    u_ex = u_ex.to(device)\n",
    "    u_dx_ex = u_dx_ex.to(device)\n",
    "    u_dy_ex = u_dy_ex.to(device)\n",
    "    net = net.to(device)\n",
    "    if net.hight.shape[0]>3000:\n",
    "        use_batch=True\n",
    "    else:\n",
    "        use_batch=False\n",
    "    with torch.no_grad():\n",
    "        if use_batch:\n",
    "            dataset = Data.TensorDataset(X)\n",
    "            data_iter = Data.DataLoader(dataset=dataset, batch_size=2000, shuffle=False)\n",
    "            u = None\n",
    "            u_dx = None\n",
    "            u_dy = None\n",
    "            for x in data_iter:\n",
    "                x_part = x[0].to(device)\n",
    "                u_part = net(x_part).flatten()\n",
    "                u_dx_part = net.cal_dx(x_part).flatten()\n",
    "                u_dy_part = net.cal_dy(x_part).flatten()\n",
    "                if u is None:\n",
    "                    u = u_part\n",
    "                    u_dx = u_dx_part\n",
    "                    u_dy = u_dy_part\n",
    "                else:\n",
    "                    u = torch.cat((u,u_part),0)\n",
    "                    u_dx =  torch.cat((u_dx,u_dx_part),0)\n",
    "                    u_dy =  torch.cat((u_dy,u_dy_part),0)\n",
    "                # torch.cuda.empty_cache()\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "            u = net(X).flatten()\n",
    "            u_dx = net.cal_dx(X).flatten()\n",
    "            u_dy = net.cal_dy(X).flatten()\n",
    "    Rel_L2 = torch.norm(u_ex-u)/torch.norm(u_ex)  \n",
    "    Rel_Li = torch.max(torch.abs(u-u_ex))/torch.max(torch.abs(u_ex))\n",
    "    Rel_H1 = torch.sqrt(torch.norm(u_ex-u)**2+torch.norm(u_dx_ex-u_dx)**2+torch.norm(u_dy_ex-u_dy)**2)/\\\n",
    "                torch.sqrt(torch.norm(u_ex)**2+ torch.norm(u_dx_ex)**2+torch.norm(u_dy_ex)**2)\n",
    "    print(\"Rel.L2=\",Rel_L2.cpu(),\",Rel.Li=\",Rel_Li.cpu(),\",Rel.H1=\",Rel_H1.cpu())\n",
    "    losswriter.add_scalar('Rel_L2',Rel_L2.cpu().item())\n",
    "    losswriter.add_scalar('Rel_Li',Rel_Li.cpu().item())\n",
    "    losswriter.add_scalar('Rel_H1',Rel_H1.cpu().item())\n",
    "    return Rel_L2,Rel_Li,Rel_H1\n",
    "\n",
    "\n",
    "#去除无效基函数\n",
    "def drop_bf(net,tol=10):\n",
    "    net = net.cpu()\n",
    "    print(f'The number of RBFs before discarding：{net.hight.shape[0]}')\n",
    "    c, h = net.center.detach(), net.hight.detach()\n",
    "    index = torch.where(abs(h) > tol)[0]\n",
    "    c1 = torch.index_select(c, 0, index)\n",
    "    h1 = torch.index_select(h, 0, index)\n",
    "    net.center = nn.Parameter(c1)\n",
    "    net.hight = nn.Parameter(h1)\n",
    "    print(f'The number of RBFs after discarding：{net.hight.shape[0]}')\n",
    "    return net\n",
    "\n",
    "#初始化SFSNN网络的中心分布\n",
    "def generate_center(N):\n",
    "    n = int(math.sqrt(N))\n",
    "    x0 = torch.linspace(-1,1,n)\n",
    "    mx,my = torch.meshgrid((x0,x0))\n",
    "    center = torch.cat((mx.reshape(-1,1),my.reshape(-1,1)),1)\n",
    "    return center\n",
    "\n",
    "#定义SFSNN网络\n",
    "class BesselNet(torch.nn.Module):\n",
    "    def __init__(self,N=32):\n",
    "        super(BesselNet, self).__init__()\n",
    "        torch.manual_seed(1)\n",
    "        # self.center = nn.Parameter((r_bd-l_bd)*torch.rand(N,2)+l_bd)\n",
    "        # self.center = nn.Parameter(calculate_circle_coordinates(N,2))\n",
    "        self.center = nn.Parameter(generate_center(N))\n",
    "        self.hight = nn.Parameter(torch.rand(N,dtype=torch.float64))\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = get_u(x,self.center,self.hight)\n",
    "        return u\n",
    "\n",
    "    def cal_dx(self,x):\n",
    "        return get_u_dx(x,net.center,net.hight)\n",
    "\n",
    "    def cal_dy(self,x):\n",
    "        return get_u_dy(x,net.center,net.hight)\n",
    "\n",
    "#计算LASSO问题的系数矩阵和右端向量\n",
    "def cal_Jacobi(net,x_bd):\n",
    "    t1 = time.time()\n",
    "    with torch.no_grad():\n",
    "        A = get_u_dh(x_bd,net.center.data)\n",
    "        f = generate_bd_term(x_bd)\n",
    "    t2 = time.time()\n",
    "    print('计算系数矩阵耗时=',t2-t1)\n",
    "    print('A.shape',A.shape,f.shape)\n",
    "    return A.detach(),f.detach()\n",
    "\n",
    "#求解线性最小二乘问题：Ax=f\n",
    "def solve_coeff(net,A,f):  #solve  Ax=f\n",
    "    test_err(net)\n",
    "    net = net.cpu()\n",
    "    print(\"A的条件数=\",torch.linalg.cond(A))\n",
    "    index1 = torch.where(abs(net.hight) > 1e-5)[0]\n",
    "    print(\"初始有效基函数个数=\",index1.shape[0])\n",
    "    err_ini = torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f)\n",
    "    print(\"初始误差,err_norm=\",torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f))\n",
    "    t1 = time.time()\n",
    "    \n",
    "    bestP = torch.linalg.lstsq(A,f,driver='gelsd')[0] #‘gels’ , ‘gelsy’ , ‘gelsd , ‘gelss’\n",
    "    t2 = time.time()\n",
    "    print(\"solve time=\",t2-t1)\n",
    "    net.hight = nn.Parameter(bestP.flatten())\n",
    "    print(\"最小二乘求解后,err_norm=\",torch.norm(torch.matmul(A,bestP).reshape(-1,1)-f))\n",
    "    print(\"最小二乘求解后,相对误差:\")\n",
    "    test_err(net)\n",
    "    net = net.to(device)\n",
    "    return net\n",
    "\n",
    "#记录损失以及各种超参数等等\n",
    "class LossWriter:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = {}\n",
    "\n",
    "    def add_scalar(self, tag, scalar_value):\n",
    "        if tag not in self.data:\n",
    "            self.data[tag] = []\n",
    "        self.data[tag].append(scalar_value)\n",
    "        \n",
    "    def save(self):\n",
    "        # 保存数据为npz格式\n",
    "        np.savez(self.filename, **self.data)\n",
    "\n",
    "\n",
    "#求解LASSO问题：||Ax-f||+\\lam||x||_1\n",
    "def solve_coeff_lasso(net,A,f,lam=0.001,cri=None):  #solve  Ax=f\n",
    "    test_err(net)\n",
    "    net = net.cpu()\n",
    "    print(\"A的条件数=\",torch.linalg.cond(A))\n",
    "    index1 = torch.where(abs(net.hight) > 1e-5)[0]\n",
    "    print(\"初始有效基函数个数=\",index1.shape[0])\n",
    "    err_ini = torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f)\n",
    "    print(\"初始误差,err_norm=\",torch.norm(torch.matmul(A,net.hight.data).reshape(-1,1)-f))\n",
    "    t1 = time.time()\n",
    "    clf = Lasso(lam,fit_intercept=False)\n",
    "    clf.fit(A,f) \n",
    "    print('使用指定的lam=',lam)\n",
    "    h = torch.tensor(clf.coef_)\n",
    "    t2 = time.time()\n",
    "    print('lasso 求解耗时=',t2-t1)\n",
    "    net.hight = nn.Parameter(h.flatten())\n",
    "    print(\"lasso求解后,err_norm=\",torch.norm(torch.matmul(A,h).reshape(-1,1)-f))\n",
    "    print(\"lasso求解后,相对误差:\")\n",
    "    test_err(net)\n",
    "    net = net.to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a99ecf2-f064-45ec-9e2f-bc909b3effa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tol_c= 0.0025\n",
      "Rel.L2= tensor(1.78163547e-07) ,Rel.Li= tensor(1.91631516e-07) ,Rel.H1= tensor(1.78131115e-07)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'losswriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 164\u001b[0m\n\u001b[0;32m    162\u001b[0m net \u001b[38;5;241m=\u001b[39m BesselNet(N)\n\u001b[0;32m    163\u001b[0m net \u001b[38;5;241m=\u001b[39m load_model(net)\n\u001b[1;32m--> 164\u001b[0m test_err(net)\n\u001b[0;32m    165\u001b[0m losswriter \u001b[38;5;241m=\u001b[39m LossWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss/loss_exam1_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(k,N))\n\u001b[0;32m    166\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m,k)\n",
      "Cell \u001b[1;32mIn[10], line 180\u001b[0m, in \u001b[0;36mtest_err\u001b[1;34m(net, n)\u001b[0m\n\u001b[0;32m    177\u001b[0m Rel_H1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mnorm(u_ex\u001b[38;5;241m-\u001b[39mu)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dx_ex\u001b[38;5;241m-\u001b[39mu_dx)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dy_ex\u001b[38;5;241m-\u001b[39mu_dy)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\\\n\u001b[0;32m    178\u001b[0m             torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mnorm(u_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(u_dx_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(u_dy_ex)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRel.L2=\u001b[39m\u001b[38;5;124m\"\u001b[39m,Rel_L2\u001b[38;5;241m.\u001b[39mcpu(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Rel.Li=\u001b[39m\u001b[38;5;124m\"\u001b[39m,Rel_Li\u001b[38;5;241m.\u001b[39mcpu(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Rel.H1=\u001b[39m\u001b[38;5;124m\"\u001b[39m,Rel_H1\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m--> 180\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRel_L2\u001b[39m\u001b[38;5;124m'\u001b[39m,Rel_L2\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    181\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRel_Li\u001b[39m\u001b[38;5;124m'\u001b[39m,Rel_Li\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    182\u001b[0m losswriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRel_H1\u001b[39m\u001b[38;5;124m'\u001b[39m,Rel_H1\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'losswriter' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def caldc(c1,c2):\n",
    "    dc = (abs(c1-c2)).sum(-1)\n",
    "    print(\"center变动最大的:\",torch.max(dc).cpu().item())\n",
    "\n",
    "def caldh(h1,h2):\n",
    "    print(\"hight中变动最大的:\",torch.max(abs(h1-h2)).cpu().item())\n",
    "\n",
    "#合并基函数，将两个中心距离较小的基函数合并为一个\n",
    "def merge_bf(center,hight,tol=0.01):\n",
    "    distances = torch.cdist(center,center)\n",
    "    # print(distances)\n",
    "    c_new,h_new = [],[]\n",
    "    index = torch.arange(distances.shape[0])\n",
    "    i = 0\n",
    "    while (len(index)>0)&(i<hight.shape[0]):\n",
    "        dis = distances[i,:]\n",
    "        index_i = torch.where(dis<tol)[0]\n",
    "        c = 0\n",
    "        h = 0\n",
    "        # print('i=',i,'dis=',dis)\n",
    "        num= len(index)\n",
    "        for j in index_i:\n",
    "            if j not in index:\n",
    "                continue\n",
    "            c += center[j,:]\n",
    "            h += hight[j]\n",
    "            if len(index)==1:\n",
    "                index= []\n",
    "            else:\n",
    "                index_del = np.where(index==j)\n",
    "                index = np.delete(index,index_del) \n",
    "            # print('j=',j,'index=',index)\n",
    "        # print(min(len(index_i),num))\n",
    "        # print('c1=',c/min(len(index_i),num),'h1=',h)\n",
    "        c_new.append(c/min(len(index_i),num))\n",
    "        h_new.append(h)\n",
    "        # print('index=',index,len(index))\n",
    "        if len(index)>0:\n",
    "            i = index[0]\n",
    "        else:\n",
    "            i = i+1\n",
    "    c_new = torch.tensor(np.array(c_new))\n",
    "    h_new = torch.tensor(np.array(h_new))\n",
    "    print('合并前的中心=',center,'合并前的系数=',hight)\n",
    "    print('合并后的中心=',c_new,'合并后的系数=',h_new)\n",
    "    return c_new,h_new\n",
    "    \n",
    "#训练SFSNN网络\n",
    "def train(net,x_bd,losswriter,lr,MaxNiter,lam,tol,tol_c):\n",
    "    t_all = 0.0\n",
    "    test_err(net)\n",
    "    g = generate_bd_term(x_bd)   #边界控制项\n",
    "    net = net.to(device)\n",
    "    dataset = Data.TensorDataset(x_bd,g)\n",
    "    data_iter = Data.DataLoader(dataset=dataset, batch_size=int(x_bd.shape[0]), shuffle=False)\n",
    "    optimizer = optims.Adam([{\"params\":net.center,\"lr\":lr},{\"params\":net.hight,\"lr\":lr}])\n",
    "    for Niter in range(1, MaxNiter):\n",
    "        l_bd_sum = 0.0\n",
    "        t1 = time.time()\n",
    "        for x_bd_batch,g_batch in data_iter:\n",
    "            x_bd_batch = x_bd_batch.to(device)\n",
    "            g_batch = g_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                u_bd = get_u(x_bd_batch,net.center,net.hight)  \n",
    "                u_bd_dc = get_u_dc(x_bd_batch,net.center,net.hight)\n",
    "                u_bd_dh = get_u_dh(x_bd_batch,net.center)\n",
    "            c1 = net.center.clone()\n",
    "            h1 = net.hight.clone()\n",
    "            l_bd = ((u_bd-g_batch)**2).sum() \n",
    "            net.center.grad = (2*(u_bd-g_batch).unsqueeze(-1)*u_bd_dc).sum(0)\n",
    "            net.hight.grad = (2*(u_bd-g_batch)*u_bd_dh).sum(0)\n",
    "            optimizer.step()\n",
    "            l_bd_sum+=l_bd.cpu().item()\n",
    "        c2 = net.center.data\n",
    "        h2 = net.hight.data\n",
    "       \n",
    "        t2 = time.time()\n",
    "        t_all += t2-t1\n",
    "        if (Niter%200==0)&(optimizer.param_groups[0]['lr']>=0.0001):\n",
    "            for i in range(len(optimizer.param_groups)):\n",
    "                optimizer.param_groups[i]['lr']=0.1*optimizer.param_groups[i]['lr']\n",
    "        print('k=%d,t_all=%.3f,t_Niter=%.3f,Niter:%d,l_bd:%.8f,lr:%.8f' \n",
    "            % (k,t_all,t2-t1, Niter, l_bd_sum,optimizer.param_groups[0]['lr']))\n",
    "        if Niter%10==0:\n",
    "            torch.save(net.state_dict(), 'model/2d_exam1_%d.pth'%int(k))\n",
    "            test_err(net)\n",
    "            losswriter.save()\n",
    "            caldc(c1,c2)\n",
    "            caldh(h1,h2)\n",
    "            print('center=',net.center.data,'hight=',net.hight.data)\n",
    "            plot_center(net)\n",
    "            losswriter.add_scalar('N_bf',net.hight.data.cpu().shape[0])\n",
    "            \n",
    "        if (Niter%1000==0)&(net.hight.shape[0]>1)&(Niter<MaxNiter-500):\n",
    "            net = net.cpu()\n",
    "            net = drop_bf(net,tol)\n",
    "            center_new,hight_new = merge_bf(net.center.data,net.hight.data,tol_c)\n",
    "            net.center = nn.Parameter(center_new)\n",
    "            net.hight = nn.Parameter(hight_new)\n",
    "            A,f = cal_Jacobi(net,x_bd.cpu())\n",
    "            net = solve_coeff_lasso(net,A,f,lam)\n",
    "            net = drop_bf(net,tol)\n",
    "            plot_center(net)\n",
    "            print('center=',net.center.data,'hight=',net.hight.data)\n",
    "            net = net.to(device)\n",
    "            optimizer = optims.Adam([{\"params\":net.center,\"lr\":lr},\\\n",
    "                                     {\"params\":net.hight,\"lr\":lr}])\n",
    "    net = net.cpu()\n",
    "    x_bd = x_bd.cpu()\n",
    "    A,f = cal_Jacobi(net,x_bd)\n",
    "    net = solve_coeff(net,A,f)\n",
    "    torch.save(net.state_dict(), 'model/2d_exam1_%d.pth'%int(k))\n",
    "    test_err(net)\n",
    "    losswriter.save()\n",
    "    plot_center(net,save_path='imgs/2d_exam1/k_%d_final_center.png'%k)\n",
    "    return net\n",
    "\n",
    "#绘制基函数的中心分布\n",
    "def plot_center(net,num=2,save_path=None):\n",
    "    # index = torch.where(abs(net.hight.data.cpu()) > 1e-5)[0]\n",
    "    top_values, index = torch.topk(abs(net.hight.data.cpu()), k=num, largest=True)\n",
    "    print('前%d个基函数系数='%num,top_values,',所有系数=',net.hight.data.cpu())\n",
    "    print('总基函数个数:',net.hight.shape[0],'绘制前%d个基函数'%num)\n",
    "    plt.grid(linestyle=\"--\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.scatter(exact_center[:,0],exact_center[:,1],c='r',marker='o',label='wave_source')\n",
    "    blue_label_added = False\n",
    "    yellow_label_added = False\n",
    "    for i in range(len(net.hight.data.cpu())):\n",
    "        \n",
    "        if not yellow_label_added:\n",
    "            plt.scatter(net.center.data.cpu()[i,0],net.center.data.cpu()[i,1],c='b',marker='+',label='pred_wave_source')\n",
    "            yellow_label_added = True\n",
    "        else:\n",
    "            plt.scatter(net.center.data.cpu()[i,0],net.center.data.cpu()[i,1],c='b',marker='+')\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([-1,1])\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "#加载已训练模型\n",
    "def load_model(net):\n",
    "    model = torch.load('model/2d_exam1_%d.pth'%int(k),map_location='cuda:0')\n",
    "    net.center = nn.Parameter(model['center'])\n",
    "    net.hight = nn.Parameter(model['hight'])\n",
    "    return net\n",
    "\n",
    "k = 200\n",
    "lr = 0.01\n",
    "MaxNiter = 3000\n",
    "n_bd = 2*k\n",
    "N = int(k)**2\n",
    "tol = 0.001\n",
    "tol_c = 0.5/k\n",
    "print('tol_c=',tol_c)\n",
    "torch.manual_seed(1)\n",
    "lam = 0.001#0.1,0.01,,0.0001,0.00001,0.000001\n",
    "\n",
    "x_bd = SampleBoundPoints(n_bd)\n",
    "net = BesselNet(N)\n",
    "net = load_model(net)\n",
    "test_err(net)\n",
    "losswriter = LossWriter('loss/loss_exam1_%d_%d.npz'%(k,N))\n",
    "losswriter.add_scalar('k',k)\n",
    "losswriter.add_scalar('MaxNiter',MaxNiter)\n",
    "losswriter.add_scalar('n_bd',n_bd)\n",
    "losswriter.add_scalar('lr',lr)\n",
    "losswriter.add_scalar('N',N)\n",
    "losswriter.add_scalar('lam',lam)\n",
    "losswriter.add_scalar('N_bf',net.hight.data.cpu().shape[0])\n",
    "losswriter.add_scalar('tol',tol)\n",
    "losswriter.add_scalar('tol_c',tol_c)\n",
    "# net = BesselNet(N)\n",
    "# A,f = cal_Jacobi(net,x_bd)\n",
    "# net = solve_coeff_lasso(net,A,f,lam)#\n",
    "# net = drop_bf(net,tol)\n",
    "# # torch.save(net.state_dict(), 'model/2d_exam1_%d_init.pth'%int(k))\n",
    "# # L2,_,_= test_err(net)\n",
    "# # print('lam=',lam,',L2=',L2)\n",
    "# plot_center(net,save_path='imgs/2d_exam1/k_%d_init_center.png'%k)#\n",
    "# train(net,x_bd,losswriter,lr,MaxNiter,lam,tol,tol_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116f174",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
